{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b63434",
   "metadata": {},
   "source": [
    "## **Introduction** ##"
    "This autoencoder takes the feature data obtained from data/audio_cut as input and performs dimensionality reduction in an unsupervised manner (no labels required).\n",
    "features1 and features2 should be loaded with the training set and validation set data, respectively. The reduced-dimension data will then be saved to the specified path.\n",
    "If you want to obtain the dimensionality-reduced results for the test set, replace features1 and features2 with the training set data and test set data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc1ab3-5adf-4da9-b6e8-4877a063f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "features1 = torch.load('/path/to/your/train_features.pt')\n",
    "features2 = torch.load('/path/to/your/val_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aed325-78c8-423f-9e8e-193dd060ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)              \n",
    "    np.random.seed(seed)            \n",
    "    torch.manual_seed(seed)           \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  \n",
    "        torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True   \n",
    "    torch.backends.cudnn.benchmark = False       \n",
    "\n",
    "set_seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f7c15-e724-4f83-89f5-8f2dea636ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(features):\n",
    "    mean = features.mean((0, 1), keepdims=True)  \n",
    "    std = features.std((0, 1), keepdims=True)    \n",
    "    standardized_features = (features - mean) / (std + 1e-8)  \n",
    "    return standardized_features\n",
    "features1=preprocess_data(features1)\n",
    "features2=preprocess_data(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc33f1f-708b-4315-a4c0-1c833876253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, latent_channels):\n",
    "        super(ConvAutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=latent_channels, kernel_size=3,padding=1)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=latent_channels, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(in_channels=128, out_channels=input_channels, kernel_size=3,padding=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return latent, reconstructed\n",
    "\n",
    "def train_autoencoder_with_early_stopping(\n",
    "    model, train_data, val_data, epochs=50, lr=0.001, batch_size=64, patience=5, min_delta=0.001\n",
    "):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    criterion = nn.MSELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "    epochs_no_improve = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            _, reconstructed = model(batch)\n",
    "            loss = criterion(reconstructed, batch) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in val_loader:\n",
    "                _, reconstructed_val = model(val_batch)\n",
    "                val_loss = criterion(reconstructed_val, val_batch)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "\n",
    "        val_loss = epoch_val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            epochs_no_improve = 0  \n",
    "            best_model_wts = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}. Best epoch: {best_epoch}, Best Val Loss: {best_val_loss:.6f}\")\n",
    "            break\n",
    "            \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    print(f\"Model restored to epoch {best_epoch} with Val Loss: {best_val_loss:.6f}\")\n",
    "\n",
    "    return model, train_losses, val_losses, best_epoch\n",
    "\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, val_losses=None):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    if val_losses is not None:\n",
    "        plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Reconstruction Loss (MSE)\")\n",
    "    plt.title(\"Training and Validation Reconstruction Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def extract_features(model, data, save_path=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        latent, _ = model(data)\n",
    "\n",
    "    latent_np = latent.numpy()\n",
    "\n",
    "    if save_path:\n",
    "        import numpy as np\n",
    "        np.save(save_path, latent_np)\n",
    "        print(f\"Low-dimensional features saved to: {save_path}\")\n",
    "\n",
    "    return latent_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ccd79-a0d4-4209-abb7-6ee940074731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    train_data = features1 \n",
    "    test_data = features2 \n",
    "    train_data = train_data.permute(0, 2, 1)\n",
    "    test_data=test_data.permute(0, 2, 1)\n",
    "\n",
    "    folder_path = \"2020/CV\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)  \n",
    "        print(f\"Created folder: {folder_path}\")\n",
    "\n",
    "    autoencoder = ConvAutoEncoder(input_channels=768, latent_channels=32)\n",
    "\n",
    "    autoencoder, train_losses, val_losses,best_epoch = train_autoencoder_with_early_stopping(\n",
    "        autoencoder, train_data, test_data, epochs=200, lr=0.001, batch_size=16\n",
    "    )\n",
    "\n",
    "    plot_losses(train_losses, val_losses)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262e1c3-af06-46ce-ae43-19892e914656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = extract_features(autoencoder, train_data)\n",
    "train_features = np.transpose(train_features, (0, 2, 1))\n",
    "train_file_path = os.path.join(folder_path, \"your_train_features_auto.npy\")\n",
    "np.save(train_file_path, train_features)\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Train features saved at: {train_file_path}\")\n",
    "\n",
    "\n",
    "test_features = extract_features(autoencoder, test_data)\n",
    "test_features = np.transpose(test_features, (0, 2, 1))\n",
    "test_file_path = os.path.join(folder_path, \"your_val_features_auto.npy\")\n",
    "np.save(test_file_path, test_features)\n",
    "\n",
    "print(f\"Test features shape: {test_features.shape}\")\n",
    "print(f\"Test features saved at: {test_file_path}\")\n",
    "print(f\"Training completed. Best epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f6984-3e17-4f42-a338-bb3c281a8672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd5115-e69e-42ea-8385-9ef16b9a6867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
