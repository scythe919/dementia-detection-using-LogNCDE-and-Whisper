{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addf3f00",
   "metadata": {},
   "source": [
    "This code takes two types of input data:  \n",
    "1) The feature data obtained from `data/autoencoder` \n ",
    "2) The segment indices from `data/audio_cut`  \n",
    
   "To count the number of original audio files, an intermediate code block requires the path to the audio files as additional input. \n\n" ,
    
    "The final output generates two Excel files:  \n",
    "1) The first file stores the evaluation metrics obtained on the test set  \n",
    "2) The second file contains the predicted labels for each audio file in the test set  \n\n",
    
   "Note: The indices from `data/audio_cut` are used to map the segment-level predictions back to their corresponding original audio files for final evaluation and reporting.\n"
     
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b246d8-a5e3-4092-8578-eabde8f2990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bfa26e-5307-4c37-ad38-c9ce12b72683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import diffrax\n",
    "import equinox as eqx \n",
    "import IPython\n",
    "import jax \n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp  \n",
    "import jax.random as jr \n",
    "import jax.scipy as jsp\n",
    "import librosa\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "import optax  \n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from jax import nn as jnn\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torchaudio.utils import download_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2605877-1af4-4591-8b82-cb6e61628da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "\n",
    "def binary_operator_diag(element_i, element_j):\n",
    "    a_i, bu_i = element_i\n",
    "    a_j, bu_j = element_j\n",
    "    return a_j * a_i, a_j * bu_i + bu_j\n",
    "\n",
    "\n",
    "class GLU(eqx.Module):\n",
    "    w1: eqx.nn.Linear\n",
    "    w2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, key):\n",
    "        w1_key, w2_key = jr.split(key, 2)\n",
    "        self.w1 = eqx.nn.Linear(input_dim, output_dim, use_bias=True, key=w1_key)\n",
    "        self.w2 = eqx.nn.Linear(input_dim, output_dim, use_bias=True, key=w2_key)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.w1(x) * jax.nn.sigmoid(self.w2(x))\n",
    "\n",
    "\n",
    "class LRULayer(eqx.Module):\n",
    "    nu_log: jnp.ndarray\n",
    "    theta_log: jnp.ndarray\n",
    "    B_re: jnp.ndarray\n",
    "    B_im: jnp.ndarray\n",
    "    C_re: jnp.ndarray\n",
    "    C_im: jnp.ndarray\n",
    "    D: jnp.ndarray\n",
    "    gamma_log: jnp.ndarray\n",
    "\n",
    "    def __init__(self, N, H, r_min=0, r_max=1, max_phase=6.28, *, key):\n",
    "        u1_key, u2_key, B_re_key, B_im_key, C_re_key, C_im_key, D_key = jr.split(key, 7)\n",
    "\n",
    "        # N: state dimension, H: model dimension\n",
    "        # Initialization of Lambda is complex valued distributed uniformly on ring\n",
    "        # between r_min and r_max, with phase in [0, max_phase].\n",
    "        u1 = jr.uniform(u1_key, shape=(N,))\n",
    "        u2 = jr.uniform(u2_key, shape=(N,))\n",
    "        self.nu_log = jnp.log(\n",
    "            -0.5 * jnp.log(u1 * (r_max**2 - r_min**2) + r_min**2)\n",
    "        )\n",
    "        self.theta_log = jnp.log(max_phase * u2)\n",
    "\n",
    "        # Glorot initialized Input/Output projection matrices\n",
    "        self.B_re = jr.normal(B_re_key, shape=(N, H)) / jnp.sqrt(2 * H)\n",
    "        self.B_im = jr.normal(B_im_key, shape=(N, H)) / jnp.sqrt(2 * H)\n",
    "        self.C_re = jr.normal(C_re_key, shape=(H, N)) / jnp.sqrt(N)\n",
    "        self.C_im = jr.normal(C_im_key, shape=(H, N)) / jnp.sqrt(N)\n",
    "        self.D = jr.normal(D_key, shape=(H,))\n",
    "\n",
    "        # Normalization factor\n",
    "        diag_lambda = jnp.exp(-jnp.exp(self.nu_log) + 1j * jnp.exp(self.theta_log))\n",
    "        self.gamma_log = jnp.log(jnp.sqrt(1 - jnp.abs(diag_lambda) ** 2))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Materializing the diagonal of Lambda and projections\n",
    "        Lambda = jnp.exp(-jnp.exp(self.nu_log) + 1j * jnp.exp(self.theta_log))\n",
    "        B_norm = (self.B_re + 1j * self.B_im) * jnp.expand_dims(\n",
    "            jnp.exp(self.gamma_log), axis=-1\n",
    "        )\n",
    "        C = self.C_re + 1j * self.C_im\n",
    "        # Running the LRU + output projection\n",
    "        Lambda_elements = jnp.repeat(Lambda[None, ...], x.shape[0], axis=0)\n",
    "        Bu_elements = jax.vmap(lambda u: B_norm @ u)(x)\n",
    "        elements = (Lambda_elements, Bu_elements)\n",
    "        _, inner_states = jax.lax.associative_scan(\n",
    "            binary_operator_diag, elements\n",
    "        ) \n",
    "        y = jax.vmap(lambda z, u: (C @ z).real + (self.D * u))(inner_states, x)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class LRUBlock(eqx.Module):\n",
    "    lru: LRULayer\n",
    "    glu: GLU\n",
    "    drop: eqx.nn.Dropout\n",
    "\n",
    "    def __init__(self, N, H, r_min=0, r_max=1, max_phase=6.28, drop_rate=0.1, *, key):\n",
    "        lrukey, glukey = jr.split(key, 2)\n",
    "        self.lru = LRULayer(N, H, r_min, r_max, max_phase, key=lrukey)\n",
    "        self.glu = GLU(H, H, key=glukey)\n",
    "        self.drop = eqx.nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def __call__(self, x, *, key):\n",
    "        dropkey1, dropkey2 = jr.split(key, 2)\n",
    "        skip = x\n",
    "        x = self.lru(x)\n",
    "        x = self.drop(jax.nn.gelu(x), key=dropkey1)\n",
    "        x = jax.vmap(self.glu)(x)\n",
    "        x = self.drop(x, key=dropkey2)\n",
    "        x = skip + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class LRU(eqx.Module):\n",
    "    linear_encoder: eqx.nn.Linear\n",
    "    blocks: List[LRUBlock]\n",
    "    linear_layer: eqx.nn.Linear\n",
    "    classification: bool\n",
    "    output_step: int\n",
    "    stateful: bool = True\n",
    "    nondeterministic: bool = True\n",
    "    lip2: bool = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_blocks,\n",
    "        data_dim,\n",
    "        N,\n",
    "        H,\n",
    "        output_dim,\n",
    "        classification,\n",
    "        output_step,\n",
    "        r_min=0,\n",
    "        r_max=1,\n",
    "        max_phase=6.28,\n",
    "        drop_rate=0.1,\n",
    "        *,\n",
    "        key\n",
    "    ):\n",
    "        linear_encoder_key, *block_keys, linear_layer_key = jr.split(\n",
    "            key, num_blocks + 2\n",
    "        )\n",
    "        self.linear_encoder = eqx.nn.Linear(data_dim, H, key=linear_encoder_key)\n",
    "        self.blocks = [\n",
    "            LRUBlock(N, H, r_min, r_max, max_phase, drop_rate, key=key)\n",
    "            for key in block_keys\n",
    "        ]\n",
    "        self.linear_layer = eqx.nn.Linear(H, 1, key=linear_layer_key)\n",
    "        self.classification = classification\n",
    "        self.output_step = output_step\n",
    "\n",
    "    def __call__(self, x,key,*,inference=False):\n",
    "        dropkeys = jr.split(key, len(self.blocks))\n",
    "        x = x[:, 1:] \n",
    "        x = jax.vmap(self.linear_encoder)(x)\n",
    "        for block, key in zip(self.blocks, dropkeys):\n",
    "            x = block(x,key=key)\n",
    "        x = jnp.mean(x, axis=0)\n",
    "        x = self.linear_layer(x)\n",
    "        (x,) = jnn.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d7a25-9c51-43ad-bf84-b3f1e9e06059",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = torch.load('/path/to/your/train_features_auto.pt')\n",
    "features2 = torch.load('/path/to/your/test_features_auto.pt')\n",
    "\n",
    "indices_train = torch.load('/path/to/your/train_indices.pt')\n",
    "indices_test = torch.load('/path/to/your/test_indices.pt')\n",
    "labels1=torch.load('/path/to/your/train_labels.pt')\n",
    "labels2=torch.load('/path/to/your/test_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b99e98-2353-4a3b-a64f-14f2600417d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = features1\n",
    "features_np_test =features2\n",
    "labels1_np=labels1.detach().cpu().numpy()\n",
    "labels2_np=labels2.detach().cpu().numpy()\n",
    "\n",
    "features_jax = jnp.array(features_np)\n",
    "features_jax_test=jnp.array(features_np_test)\n",
    "labels_jax=jnp.array(labels1_np)\n",
    "labels_jax_test=jnp.array(labels2_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a542897-04cb-4e6a-89c7-239e1f685985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(features):\n",
    "    mean = features.mean((0, 1), keepdims=True)  \n",
    "    std = features.std((0, 1), keepdims=True)   \n",
    "    standardized_features = (features - mean) / (std + 1e-8)  # 防止除以零\n",
    "    \n",
    "    return standardized_features\n",
    "\n",
    "def get_data(features):\n",
    "    ts = jnp.linspace(0,1, features.shape[1])\n",
    "    ts1 = jnp.repeat(ts[None, :], features.shape[0], axis=0)\n",
    "    normalized_features = preprocess_data(features)\n",
    "    time_steps_expanded = ts1[:, :, None]  \n",
    "    features_with_time = jnp.concatenate([time_steps_expanded,normalized_features], axis=2) \n",
    "    return features_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8340050d-9516-4b9e-baf6-c0b9784989ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=get_data(features_jax)\n",
    "X_test=get_data(features_jax_test)\n",
    "\n",
    "y_train=labels_jax\n",
    "y_test=labels_jax_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2024e9-0d84-410a-8367-aafe111c8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_audio_files(directory):\n",
    "\n",
    "    audio_extensions = ('.wav', '.mp3', '.flac', '.aac', '.ogg', '.m4a', '.wma')\n",
    "    audio_file_count = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(audio_extensions):\n",
    "                audio_file_count += 1\n",
    "\n",
    "    return audio_file_count\n",
    "\n",
    "train_ccn=count_audio_files(\"your_audio_cc_train\")\n",
    "train_cdn=count_audio_files(\"your_audio_cd_train\")\n",
    "test_ccn=count_audio_files(\"your_audio_cc_test\")\n",
    "test_cdn=count_audio_files(\"your_audio_cd_test\")\n",
    "print(\"train_ccn:\",train_ccn)\n",
    "print(\"train_cdn:\",train_cdn)\n",
    "print(\"test_ccn:\",test_ccn)\n",
    "print(\"test_cdn:\",test_cdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe3b24f-bef4-4f88-9988-49f17f3cb72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = jnp.concatenate([jnp.zeros(test_ccn), jnp.ones(test_cdn)])\n",
    "labels_train = jnp.concatenate([jnp.zeros(train_ccn), jnp.ones(train_cdn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fa4a8-3253-4577-aab5-1927e8ef9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c287a-2d39-414c-beb0-d5f76f49c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Dataloader class\n",
    "class Dataloader:\n",
    "    data: jnp.ndarray  \n",
    "    labels: jnp.ndarray  \n",
    "    size: int \n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data  \n",
    "        self.labels = labels  \n",
    "        self.size = len(data) \n",
    "\n",
    "    def loop(self, batch_size, *, key=None):\n",
    "        if batch_size == self.size:\n",
    "            yield self.data, self.labels\n",
    "\n",
    "        indices = jnp.arange(self.size) \n",
    "        while True:\n",
    "            subkey, key = jr.split(key)  \n",
    "            perm = jr.permutation(subkey, indices)  \n",
    "            start = 0\n",
    "            end = batch_size\n",
    "            while end < self.size:\n",
    "                batch_perm = perm[start:end] \n",
    "                yield self.data[batch_perm], self.labels[batch_perm]\n",
    "                start = end  \n",
    "                end = start + batch_size  \n",
    "\n",
    "# Initialise dataloaders for training and testing data\n",
    "train_dataloader = Dataloader(X_train, y_train)\n",
    "test_dataloader = Dataloader(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404be35-c1f1-4ccb-bdc6-0d4974020aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification loss function with gradient calculation\n",
    "@eqx.filter_jit\n",
    "@eqx.filter_value_and_grad\n",
    "def classification_loss(model, X, y, *, key):\n",
    "    batch_size = X.shape[0]\n",
    "    keys = jax.random.split(key, batch_size)\n",
    "    def model_forward(x, k):\n",
    "        return model(x, k, inference=False)\n",
    "\n",
    "    pred_y = jax.vmap(model_forward)(X, keys)\n",
    "    epsilon = 1e-7\n",
    "    pred_y_clipped = jnp.clip(pred_y, epsilon, 1 - epsilon)\n",
    "    loss = - ( y * jnp.log(pred_y_clipped) +  (1 - y) * jnp.log(1 - pred_y_clipped))    \n",
    "    return jnp.mean(loss)\n",
    "\n",
    "# Define the training step function with JIT compilation\n",
    "@eqx.filter_jit\n",
    "def train_step(model, X, y, opt, opt_state, *, key):\n",
    "    key, subkey = jr.split(key)\n",
    "    loss, grads = classification_loss(model, X, y,key=subkey)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params=trainable_params)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return model, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1c648-4629-46a6-8906-a07445f7b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_and_plot_roc_pr_curves(labels, predictions, plot_title_prefix=\"\"):\n",
    "    labels_np = jnp.asarray(labels)\n",
    "    predictions_np = jnp.asarray(predictions)\n",
    "\n",
    "    if labels_np.shape[0] != predictions_np.shape[0]:\n",
    "        raise ValueError(f\"Found input variables with inconsistent numbers of samples: {labels_np.shape[0]}, {predictions_np.shape[0]}\")\n",
    "\n",
    "    fpr, tpr, roc_thresholds = roc_curve(labels_np, predictions_np)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"{plot_title_prefix} AUC (ROC):\", roc_auc)\n",
    "\n",
    "    youden_j = tpr - fpr\n",
    "    best_threshold_index_roc = jnp.argmax(youden_j)\n",
    "    best_threshold_roc = roc_thresholds[best_threshold_index_roc]\n",
    "\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(labels_np, predictions_np)\n",
    "    pr_thresholds = pr_thresholds[:-1]\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_scores = jnp.nan_to_num(f1_scores, nan=0.0)  # 将 NaN 值替换为 0，避免除以零的问题\n",
    "\n",
    "    best_threshold_index_pr = jnp.argmax(f1_scores)\n",
    "\n",
    "    if best_threshold_index_pr >= len(pr_thresholds):\n",
    "        best_threshold_index_pr = len(pr_thresholds) - 1\n",
    "\n",
    "    best_threshold_pr = pr_thresholds[best_threshold_index_pr]\n",
    "\n",
    "    accuracies = []\n",
    "    for threshold in pr_thresholds:\n",
    "        preds = (predictions_np >= threshold).astype(int)\n",
    "        accuracy = accuracy_score(labels_np, preds)\n",
    "        accuracies.append(accuracy)\n",
    "    accuracies = jnp.array(accuracies)\n",
    "\n",
    "    best_threshold_index_accuracy = jnp.argmax(accuracies)\n",
    "    best_threshold_accuracy = pr_thresholds[best_threshold_index_accuracy]\n",
    "\n",
    "    return best_threshold_roc, best_threshold_pr, best_threshold_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2a847-9c32-499f-b946-fb9102befaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def save_model_results(\n",
    "    seed,\n",
    "    acc_test,\n",
    "    f1,\n",
    "    precision,\n",
    "    recall,\n",
    "    acc_test_vote,\n",
    "    f1_vote,\n",
    "    precision_vote,\n",
    "    recall_vote,\n",
    "    test_predictions1,\n",
    "    test_predictions2,\n",
    "    metrics_csv=\"metrics.csv\",\n",
    "    preds_csv=\"predictions.csv\"\n",
    "):\n",
    "\n",
    "    if not os.path.exists(metrics_csv):\n",
    "        df_metrics = pd.DataFrame(columns=[\"seed\",\"acc_test\",\"f1\",\"precision\",\"recall\",\"acc_test_vote\",\"f1_vote\",\"precision_vote\",\"recall_vote\"])\n",
    "    else:\n",
    "        df_metrics = pd.read_csv(metrics_csv)\n",
    "\n",
    "    if seed in df_metrics[\"seed\"].values:\n",
    "        print(f\"[INFO] Metrics for Seed={seed} already exist in {metrics_csv}, skipping save.\")\n",
    "    else:\n",
    "        new_row_df = pd.DataFrame([{\n",
    "            \"seed\": seed,\n",
    "            \"acc_test\": acc_test,\n",
    "            \"f1\": f1,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"acc_test_vote\": acc_test_vote,\n",
    "            \"f1_vote\": f1_vote,\n",
    "            \"precision_vote\": precision_vote,\n",
    "            \"recall_vote\": recall_vote\n",
    "        }])\n",
    "        df_metrics = pd.concat([df_metrics, new_row_df], ignore_index=True)\n",
    "        df_metrics.to_csv(metrics_csv, index=False)\n",
    "        print(f\"[SUCCESS] Saved metrics for Seed={seed} to {metrics_csv}.\")\n",
    "\n",
    "    if not os.path.exists(preds_csv):\n",
    "        df_preds = pd.DataFrame(columns=[\"seed\",\"test_predictions1\",\"test_predictions2\"])\n",
    "    else:\n",
    "        df_preds = pd.read_csv(preds_csv)\n",
    "\n",
    "    if seed in df_preds[\"seed\"].values:\n",
    "        print(f\"[INFO] Prediction list for Seed={seed} already exists in {preds_csv}, skipping save.\")\n",
    "    else:\n",
    "        test_preds1_str = str(test_predictions1)\n",
    "        test_preds2_str = str(test_predictions2)\n",
    "\n",
    "        new_row_preds_df = pd.DataFrame([{\n",
    "            \"seed\": seed,\n",
    "            \"test_predictions1\": test_preds1_str,\n",
    "            \"test_predictions2\": test_preds2_str\n",
    "        }])\n",
    "        df_preds = pd.concat([df_preds, new_row_preds_df], ignore_index=True)\n",
    "        df_preds.to_csv(preds_csv, index=False)\n",
    "        print(f\"[SUCCESS] Saved prediction list for Seed={seed} to {preds_csv}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd266a9-2195-4b31-83a7-c1b01d810b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import jax\n",
    "import optax\n",
    "import math\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def get_trainable_params(model):\n",
    "    return eqx.filter(model, eqx.is_inexact_array)\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    num_steps=415, \n",
    "    print_steps=40,  \n",
    "    batch_size=32, \n",
    "    base_lr=3.5e-4, \n",
    "    warmup_steps = 84,\n",
    "    weight_decay=0, \n",
    "    *,\n",
    "    key,\n",
    "    seed,\n",
    "):\n",
    "    global train_predictions1, test_predictions1,test_predictions2,trainable_params\n",
    "    trainable_params = get_trainable_params(model)\n",
    "\n",
    "    warmup_schedule = optax.linear_schedule(\n",
    "        init_value=0.0, \n",
    "        end_value=base_lr, \n",
    "        transition_steps=warmup_steps,  \n",
    "    )\n",
    "    \n",
    "    cosine_schedule = optax.cosine_decay_schedule(\n",
    "        init_value=base_lr,  \n",
    "        decay_steps=num_steps - warmup_steps, \n",
    "        alpha=0.01  \n",
    "    )\n",
    "    \n",
    "    lr_schedule = optax.join_schedules(\n",
    "        schedules=[warmup_schedule, cosine_schedule], \n",
    "        boundaries=[warmup_steps]  \n",
    "    )\n",
    "    \n",
    "    opt = optax.adamw(learning_rate=lr_schedule, weight_decay=weight_decay)\n",
    "    \n",
    "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "\n",
    "    test_accs = [] \n",
    "    test_accs_vote = []\n",
    "    steps = []  \n",
    "    train_accs = [] \n",
    "\n",
    "    dataset_size = X_train.shape[0]\n",
    "    steps_per_epoch = math.ceil(dataset_size / batch_size)\n",
    "    total_epochs = math.ceil(num_steps / steps_per_epoch)\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "        trainloopkey, key = jax.random.split(key)\n",
    "\n",
    "        for step, data in zip(\n",
    "            range(steps_per_epoch), train_dataloader.loop(batch_size, key=trainloopkey)\n",
    "        ):\n",
    "            start_time = time.time()\n",
    "    \n",
    "            X, y = data  \n",
    "            key, subkey = jr.split(key)\n",
    "\n",
    "            model, opt_state, loss = train_step(model, X, y, opt, opt_state, key=subkey)\n",
    "            if step == 0 or (step + 1) % print_steps == 0 or step==(steps_per_epoch - 1):\n",
    "                inference_model = eqx.nn.inference_mode(model)\n",
    "                inference_model = eqx.Partial(inference_model,inference=True)\n",
    "\n",
    "                for batch, data in zip(\n",
    "                    range(1), train_dataloader.loop(train_dataloader.size)\n",
    "                ):\n",
    "                    X, y = data\n",
    "                    keys = jax.random.split(jr.PRNGKey(0), X.shape[0])\n",
    "                    output = jax.vmap(inference_model)(X, keys)\n",
    "                    pre_train = output\n",
    "                    train_acc = jnp.mean((output > 0.5) == (y == 1))\n",
    "\n",
    "                for batch, data in zip(\n",
    "                    range(1), test_dataloader.loop(test_dataloader.size)\n",
    "                ):\n",
    "                    X, y = data\n",
    "                    keys = jax.random.split(jr.PRNGKey(0), X.shape[0])\n",
    "                    output = jax.vmap(inference_model)(X, keys)\n",
    "\n",
    "                    test_acc = jnp.mean((output > 0.5) == (y == 1))\n",
    "                if step == steps_per_epoch - 1:\n",
    "                    pre_test = output\n",
    "\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Step: {step + 1}, Loss: {loss}, Train Acc: {train_acc}, Test Acc: {test_acc}, Time: {elapsed_time:.4f} seconds\")\n",
    "    \n",
    "                steps.append(step + 1)\n",
    "        audio_segments_train = {}       \n",
    "        \n",
    "        for idx, pred in zip(indices_train[:,0], pre_train):\n",
    "            if idx.size == 1:\n",
    "                idx = int(idx.item())\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected idx size: {idx.size}, idx: {idx}\")\n",
    "            if idx in audio_segments_train:\n",
    "                audio_segments_train[idx].append(pred)\n",
    "            else:\n",
    "                audio_segments_train[idx] = [pred]\n",
    "        \n",
    "        audio_predictions_train = {idx: jnp.mean(jnp.array(preds)) for idx, preds in audio_segments_train.items()}\n",
    "\n",
    "        predictions1 = list(audio_predictions_train.values())\n",
    "        predictions1 = jnp.array(predictions1) \n",
    "\n",
    "\n",
    "        train_predictions1 = [(idx, 1 if pred >= 0.5 else 0) for idx, pred in audio_predictions_train.items()]\n",
    "\n",
    "        audio_segments_test = {}\n",
    "        for idx, pred_val in zip(indices_test[:, 0], pre_test):\n",
    "            if idx.size == 1:\n",
    "                idx = int(idx.item()) \n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected idx size: {idx.size}, idx: {idx}\")\n",
    "            if idx in audio_segments_test:\n",
    "                audio_segments_test[idx].append(pred_val)\n",
    "            else:\n",
    "                audio_segments_test[idx] = [pred_val]\n",
    "        \n",
    "        audio_predictions_test = {idx: jnp.mean(jnp.array(preds)) for idx, preds in audio_segments_test.items()}\n",
    "        audio_predictions_test_vote = {idx: 1 if jnp.sum(jnp.array(preds) > 0.5) > jnp.sum(jnp.array(preds) <= 0.5) else 0 for idx, preds in audio_segments_test.items()}\n",
    "        \n",
    "        values = jnp.array(list(audio_predictions_test.values()))\n",
    "\n",
    "        evaluate_and_plot_roc_pr_curves(labels_train, predictions1, plot_title_prefix=\"Train\")\n",
    "        evaluate_and_plot_roc_pr_curves(labels_test, values, plot_title_prefix=\"Test\")\n",
    "\n",
    "        correct_predictions_test = 0\n",
    "        predict_label=[]\n",
    "        predict_label_vote=[]\n",
    "        for idx, pred in audio_predictions_test.items():\n",
    "            label = labels_test[idx]\n",
    "            predict_label.append((pred>0.5))\n",
    "            if (pred>0.5) == label:\n",
    "                correct_predictions_test += 1\n",
    "                \n",
    "        acc_test = correct_predictions_test / len(audio_predictions_test)\n",
    "                \n",
    "        correct_predictions_test_vote = 0\n",
    "        for idx, pred in audio_predictions_test_vote.items():\n",
    "            label = labels_test[idx]\n",
    "            predict_label_vote.append(pred)\n",
    "            if pred == label:\n",
    "                correct_predictions_test_vote += 1\n",
    "\n",
    "        acc_test_vote = correct_predictions_test_vote / len(audio_predictions_test)\n",
    "\n",
    "        \n",
    "        predict_label_array=np.array(predict_label)\n",
    "        predict_label_vote_array=np.array(predict_label_vote)\n",
    "        labels_test_array=np.array(labels_test)\n",
    "\n",
    "        precision = precision_score(labels_test_array,predict_label_array)\n",
    "        precision_vote=precision_score(labels_test_array,predict_label_vote_array)\n",
    "\n",
    "        recall = recall_score(labels_test_array,predict_label_array)\n",
    "        recall_vote=recall_score(labels_test_array,predict_label_vote_array)\n",
    "\n",
    "        f1 = f1_score(labels_test_array,predict_label_array)\n",
    "        f1_vote=f1_score(labels_test_array,predict_label_vote_array)\n",
    "\n",
    "        print('acc_test:', acc_test)\n",
    "        print('acc_test_vote:', acc_test_vote)\n",
    "        test_accs.append(acc_test)\n",
    "        test_accs_vote.append(acc_test_vote)\n",
    "        if epoch==total_epochs-1:\n",
    "            predictions_list_test = []\n",
    "            for idx, preds in audio_segments_test.items():\n",
    "                mean_pred = jnp.mean(jnp.array(preds))\n",
    "                predictions_list_test.append((idx, mean_pred))\n",
    "            \n",
    "            predictions_list_test.sort(key=lambda x: x[0])\n",
    "            \n",
    "            for idx, mean_pred in predictions_list_test:\n",
    "                print(f\"Audio segment test {idx}: Prediction value {mean_pred}\")\n",
    "            test_predictions1 = [(idx, 1 if pred >= 0.5 else 0) for idx, pred in predictions_list_test]\n",
    "            test_predictions2 = [(idx, 1 if pred == 1 else 0) for idx, pred in audio_predictions_test_vote.items()]\n",
    "            save_model_results(\n",
    "                seed=seed,\n",
    "                acc_test=acc_test,\n",
    "                f1=f1,\n",
    "                precision=precision,\n",
    "                recall=recall,\n",
    "                acc_test_vote=acc_test_vote,\n",
    "                f1_vote=f1_vote,\n",
    "                precision_vote=precision_vote,\n",
    "                recall_vote=recall_vote,\n",
    "                test_predictions1=test_predictions1,\n",
    "                test_predictions2=test_predictions2,\n",
    "                metrics_csv=\"your_solution.csv\",\n",
    "                preds_csv=\"your_pred.csv\"\n",
    "            )\n",
    "        \n",
    "    return acc_test,acc_test_vote,test_accs,test_accs_vote,train_predictions1, test_predictions1,test_predictions2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e487293-cc74-4cf5-8bfa-dee010d05571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f99151-d59b-42df-9ac2-58d26ac9b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "def train_with_seeds(seeds):\n",
    "    global hyperparameters, all_train_predictions, all_test_predictions_vote, all_test_predictions, acc_seeds\n",
    "    hyperparameters = []\n",
    "    all_train_predictions = []\n",
    "    all_test_predictions = [] \n",
    "    all_test_predictions_vote = [] \n",
    "    acc_seeds = []\n",
    "    all_test_accuracies = []\n",
    "    all_test_accuracies_vote = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        key = jax.random.PRNGKey(seed)\n",
    "        modelkey, key = jax.random.split(key)\n",
    "        trainkey, key = jax.random.split(key)\n",
    "        LRU1 = LRU(\n",
    "            num_blocks,\n",
    "            data_dim,\n",
    "            ssm_dim,\n",
    "            hidden_dim,\n",
    "            label_dim,\n",
    "            classification,\n",
    "            output_step,\n",
    "            key=key,\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            print(f\"Training with seed: {seed}\")\n",
    "            train_predictions1 = []\n",
    "            test_predictions1 = []\n",
    "            test_predictions2 = []\n",
    "\n",
    "            acc_test, acc_test_vote, test_accs,test_accs_vote,train_predictions1, test_predictions1,test_predictions2 = train_model(LRU1, key=trainkey, seed=seed)\n",
    "\n",
    "            acc_test_cpu = np.array(acc_test)\n",
    "            acc_test_vote_cpu = np.array(acc_test_vote)\n",
    "            test_accs_cpu = np.array(test_accs)\n",
    "            test_accs_vote_cpu=np.array(test_accs_vote)\n",
    "\n",
    "            test_predictions1_cpu = [np.array(p) for p in test_predictions1]\n",
    "            test_predictions2_cpu = [np.array(p) for p in test_predictions2]\n",
    "\n",
    "            all_train_predictions.append(train_predictions1)\n",
    "            all_test_predictions.append(test_predictions1_cpu)\n",
    "            all_test_predictions_vote.append(test_predictions2_cpu)\n",
    "            all_test_accuracies.append(test_accs_cpu)\n",
    "            all_test_accuracies_vote.append(test_accs_vote_cpu)\n",
    "\n",
    "\n",
    "\n",
    "        finally:\n",
    "            del key\n",
    "            del modelkey\n",
    "            del trainkey\n",
    "            jax.device_put(None)\n",
    "            gc.collect()\n",
    "            jax.clear_caches() \n",
    "\n",
    "\n",
    "def vote_and_evaluate():\n",
    "    train_votes = aggregate_votes(all_train_predictions)\n",
    "    accuracy=evaluate_accuracy(train_votes, labels_train, \"Train\")\n",
    "\n",
    "    test_votes = aggregate_votes(all_test_predictions)\n",
    "    accuracy_test=evaluate_accuracy(test_votes, labels_test, \"Test\")\n",
    "    test_votes=jnp.array(list(test_votes.values()))\n",
    "\n",
    "    test_vote_votes = aggregate_votes(all_test_predictions_vote)\n",
    "    accuracy_vote_test=evaluate_accuracy(test_vote_votes, labels_test, \"Test_vote\")\n",
    "    test_vote_votes=jnp.array(list(test_vote_votes.values()))\n",
    "    \n",
    "    precision = precision_score(labels_test,test_votes)\n",
    "    print(f'Precision: {precision}')\n",
    "    \n",
    "    recall = recall_score(labels_test,test_votes)\n",
    "    print(f'Recall: {recall}')\n",
    "    \n",
    "    f1 = f1_score(labels_test,test_votes)\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "    precision = precision_score(labels_test,test_vote_votes)\n",
    "    print(f'Precision_vote: {precision}')\n",
    "    \n",
    "    recall = recall_score(labels_test,test_vote_votes)\n",
    "    print(f'Recall_vote: {recall}')\n",
    "    \n",
    "    f1 = f1_score(labels_test,test_vote_votes)\n",
    "    print(f'F1 Score_vote: {f1}')\n",
    "    \n",
    "    print('testvotes:',test_votes)\n",
    "    print('test_vote_votes:',test_vote_votes)\n",
    "\n",
    "def aggregate_votes(predictions_list_all_seeds):\n",
    "    aggregated_predictions = {}\n",
    "    for idx in range(len(predictions_list_all_seeds[0])):\n",
    "        preds = [predictions_list_all_seeds[seed_idx][idx][1] for seed_idx in range(len(predictions_list_all_seeds))]\n",
    "        vote_result = 1 if sum(pred == 1 for pred in preds) > len(preds) / 2 else 0\n",
    "        aggregated_predictions[idx] = vote_result\n",
    "    return aggregated_predictions\n",
    "\n",
    "def evaluate_accuracy(aggregated_predictions, labels, dataset_name):\n",
    "    correct_predictions = 0\n",
    "    for idx, pred in aggregated_predictions.items():\n",
    "        label = labels[idx]\n",
    "        if pred == label:\n",
    "            correct_predictions += 1\n",
    "    accuracy = correct_predictions / len(aggregated_predictions)\n",
    "    print(f'{dataset_name} Accuracy (after voting): {accuracy:.2f}')\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95411101-f80f-4f1a-afe8-bf6bf24ed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "data_dim = 768\n",
    "label_dim = 1\n",
    "vf_hidden_dim = 512\n",
    "vf_num_hidden = 3\n",
    "ode_solver_stepsize = 1 / 500\n",
    "stepsize = 15\n",
    "num_blocks=6\n",
    "ssm_dim=256\n",
    "classification=True\n",
    "output_step=1\n",
    "dt0 = None\n",
    "num_seeds = 50 \n",
    "seeds = np.arange(1001, 1050 + 1).tolist()\n",
    "train_with_seeds(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e969d6-f856-42e6-b0e9-d6db1dd8281b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a90ad6-7c1f-40c3-8b68-cae2195fb869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bef0cd-112a-47ab-965f-10ded38955ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
